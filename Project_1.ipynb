{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "299b2255",
      "metadata": {
        "id": "299b2255"
      },
      "outputs": [],
      "source": [
        "# Import stuff\n",
        "from torchvision import transforms, datasets\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import platform\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import time\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "108555a3",
      "metadata": {
        "id": "108555a3"
      },
      "outputs": [],
      "source": [
        "# Delete images in 128x128_data if needed\n",
        "normal_dir = \"128x128_data/NORMAL\"\n",
        "pneumonia_dir = \"128x128_data/PNEUMONIA\"\n",
        "\n",
        "for file in os.listdir(normal_dir) + os.listdir(pneumonia_dir):\n",
        "    img_path = os.path.join(normal_dir if file in os.listdir(normal_dir) else pneumonia_dir, file)\n",
        "    os.remove(img_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76178a00",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76178a00",
        "outputId": "f838c40a-40bb-43ec-a778-fd9ad5146405"
      },
      "outputs": [],
      "source": [
        "# Select device\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(f\"Using device: {device.type}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f630717",
      "metadata": {
        "id": "7f630717"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f93e9baa",
      "metadata": {
        "id": "f93e9baa"
      },
      "source": [
        "#### Resize the images to 128 x 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ad82ffd",
      "metadata": {
        "id": "8ad82ffd"
      },
      "outputs": [],
      "source": [
        "# Set up paths\n",
        "normal_dir = \"data/NORMAL\"\n",
        "pneumonia_dir = \"data/PNEUMONIA\"\n",
        "\n",
        "# Find which images have the smallest size\n",
        "min_size = float('inf')\n",
        "min_dimensions = (float('inf'), float('inf'))\n",
        "smallest_img_path = \"\"\n",
        "\n",
        "for image in os.listdir(normal_dir) + os.listdir(pneumonia_dir):\n",
        "    if image.endswith((\".jpeg\", \".jpg\", \".png\")):\n",
        "        img_path = os.path.join(normal_dir if image in os.listdir(normal_dir) else pneumonia_dir, image)\n",
        "        with Image.open(img_path, \"r\") as img:\n",
        "            width, height = img.size\n",
        "            if width * height < min_size:\n",
        "                min_size = width * height\n",
        "                min_dimensions = (width, height)\n",
        "                smallest_img_path = img_path\n",
        "\n",
        "print(f\"Smallest image dimensions: {min_dimensions}\")\n",
        "print(f\"Smallest image path: {smallest_img_path}\")\n",
        "\n",
        "# Paths for resized images\n",
        "resized_normal_dir = \"128x128_data/NORMAL\"\n",
        "resized_pneumonia_dir = \"128x128_data/PNEUMONIA\"\n",
        "\n",
        "# Resize all images to 128x128 pixels and save them\n",
        "for image in os.listdir(normal_dir) + os.listdir(pneumonia_dir):\n",
        "    if image.endswith((\".jpeg\", \".jpg\", \".png\")):\n",
        "        img_path = os.path.join(normal_dir if image in os.listdir(normal_dir) else pneumonia_dir, image)\n",
        "        with Image.open(img_path, \"r\") as img:\n",
        "            img = img.convert(\"L\")  # Convert to grayscale\n",
        "            width, height = img.size\n",
        "            if width > height:\n",
        "                cropped_width = 128\n",
        "                cropped_height = int(height * 128 / width)\n",
        "            else:\n",
        "                cropped_height = 128\n",
        "                cropped_width = int(width * 128 / height)\n",
        "            img = img.resize((cropped_width, cropped_height)) # Resize preserving ratio\n",
        "            left = 0\n",
        "            upper = (cropped_height - 128) // 2\n",
        "            right = 128\n",
        "            lower = upper + 128\n",
        "            img = img.crop((left, upper, right, lower)) # Center crop\n",
        "\n",
        "            if \"NORMAL\" in img_path:\n",
        "                save_path = os.path.join(resized_normal_dir, image)\n",
        "            else:\n",
        "                save_path = os.path.join(resized_pneumonia_dir, image)\n",
        "            img.save(save_path)\n",
        "\n",
        "# ~30 seconds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94c2ba9d",
      "metadata": {
        "id": "94c2ba9d"
      },
      "source": [
        "#### Ensure that all of the images are the same shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a607b95",
      "metadata": {
        "id": "7a607b95"
      },
      "outputs": [],
      "source": [
        "# Convert each image to a tensor to ensure they are all 1 x 128 x 128\n",
        "counter = 0\n",
        "for image in os.listdir(resized_normal_dir) + os.listdir(resized_pneumonia_dir):\n",
        "    if image.endswith((\".jpeg\", \".jpg\", \".png\")):\n",
        "        img_path = os.path.join(resized_normal_dir if image in os.listdir(resized_normal_dir) else resized_pneumonia_dir, image)\n",
        "        with Image.open(img_path, \"r\") as img:\n",
        "            img_tensor = transforms.ToTensor()(img)\n",
        "            if img_tensor.shape != (1, 128, 128):\n",
        "                print(f\"{image} has shape {img_tensor.shape}\")\n",
        "                counter += 1\n",
        "print(f\"{counter} images with incorrect shape\")\n",
        "\n",
        "# ~14s"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfd2efaa",
      "metadata": {
        "id": "dfd2efaa"
      },
      "source": [
        "#### Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7105ecb2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7105ecb2",
        "outputId": "74ec4ee8-3a17-4278-8280-61c866a59dea"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "# NORMAL = 0, PNEUMONIA = 1\n",
        "dataset = datasets.ImageFolder(\n",
        "    root=\"128x128_data\",\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "print(f\"Classes: {dataset.classes}\")\n",
        "\n",
        "# Split data\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = int(0.1 * len(dataset))\n",
        "val_size = len(dataset) - train_size - test_size\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "print(f\"Train size: {len(train_dataset)}\")\n",
        "print(f\"Val size: {len(val_dataset)}\")\n",
        "print(f\"Test size: {len(test_dataset)}\")\n",
        "\n",
        "# DataLoaders\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Batch size: {batch_size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86297407",
      "metadata": {
        "id": "86297407"
      },
      "source": [
        "# Fully Connected Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08651837",
      "metadata": {
        "id": "08651837"
      },
      "source": [
        "#### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b754011",
      "metadata": {
        "id": "8b754011"
      },
      "outputs": [],
      "source": [
        "# Define the network\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_dim, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2048, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 2)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11d951cd",
      "metadata": {
        "id": "11d951cd"
      },
      "source": [
        "#### Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9fc2f0a",
      "metadata": {
        "id": "b9fc2f0a"
      },
      "outputs": [],
      "source": [
        "# Define the training parameters\n",
        "model = MLP(128*128).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
        "epochs = 100\n",
        "history = {\n",
        "    \"train_loss\": [], \"train_acc\": [],\n",
        "    \"val_loss\":   [], \"val_acc\":   []\n",
        "}\n",
        "\n",
        "# Calculate accuracy from logits\n",
        "def accuracy_from_logits(logits, y):\n",
        "    preds = logits.argmax(1)  # choose class with highest predicted score\n",
        "    return (preds == y).float().mean().item()  # fraction of correct predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22484aef",
      "metadata": {
        "id": "22484aef"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a88ccb4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a88ccb4",
        "outputId": "d7654a33-c93d-4be5-fd6e-26bf4948bb06"
      },
      "outputs": [],
      "source": [
        "def train(name):\n",
        "    # Early stopping settings\n",
        "    patience = 10          # epochs to wait after last improvement\n",
        "    min_delta = 0.0        # minimum change in val_loss to qualify as improvement\n",
        "    best_val = 10e20       # track best validation loss\n",
        "    best_epoch = -1\n",
        "    patience_ctr = 0\n",
        "    best_ckpt_path = \"best.pt\"\n",
        "\n",
        "    train_start_time = time.time()\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        epoch_start_time = time.time()\n",
        "\n",
        "        # Training\n",
        "        model.train()\n",
        "        running_loss, running_correct, total = 0.0, 0, 0\n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * x.size(0)\n",
        "            running_correct += (logits.argmax(1) == y).sum().item()\n",
        "            total += x.size(0)\n",
        "\n",
        "        train_loss = running_loss / total\n",
        "        train_acc  = running_correct / total\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_running_loss, val_running_correct, val_total = 0.0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for x, y in val_loader:\n",
        "                x, y = x.to(device), y.to(device)\n",
        "                logits = model(x)\n",
        "                loss = criterion(logits, y)\n",
        "                val_running_loss += loss.item() * x.size(0)\n",
        "                val_running_correct += (logits.argmax(1) == y).sum().item()\n",
        "                val_total += x.size(0)\n",
        "\n",
        "        val_loss = val_running_loss / val_total\n",
        "        val_acc  = val_running_correct / val_total\n",
        "\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "        history[\"train_acc\"].append(train_acc)\n",
        "        history[\"val_loss\"].append(val_loss)\n",
        "        history[\"val_acc\"].append(val_acc)\n",
        "\n",
        "        epoch_time = time.time() - epoch_start_time\n",
        "        print(f\"Epoch {epoch:02d} | \"\n",
        "            f\"train: loss={train_loss:.4f}, acc={train_acc:.4f} | \"\n",
        "            f\"val: loss={val_loss:.4f}, acc={val_acc:.4f} | \"\n",
        "            f\"time: {epoch_time:.2f}s\")\n",
        "\n",
        "        # Early stopping check (monitor val_loss)\n",
        "        if val_loss < best_val - min_delta:\n",
        "            best_val = val_loss\n",
        "            best_epoch = epoch\n",
        "            patience_ctr = 0\n",
        "            # Save best checkpoint so far\n",
        "            torch.save({\n",
        "                \"epoch\": epoch,\n",
        "                \"model_state\": model.state_dict(),\n",
        "                \"optimizer_state\": optimizer.state_dict(),\n",
        "                \"history\": history,\n",
        "                \"best_val_loss\": best_val\n",
        "            }, best_ckpt_path)\n",
        "            print(f\"  -> New best val_loss {best_val:.4f} at epoch {epoch}. Saved to {best_ckpt_path}.\")\n",
        "        else:\n",
        "            patience_ctr += 1\n",
        "            if patience_ctr >= patience:\n",
        "                print(f\"\\nEarly stopping triggered at epoch {epoch} \"\n",
        "                    f\"(no improvement for {patience} epochs). Best epoch: {best_epoch}.\")\n",
        "                break\n",
        "\n",
        "    # Total training time\n",
        "    total_time = time.time() - train_start_time\n",
        "    print(f\"\\nTotal training time: {total_time:.2f}s\")\n",
        "    print(f\"Best epoch: {best_epoch} | Best val_loss: {best_val:.4f}\")\n",
        "\n",
        "    # Restore best model before final save (in case we stopped after it)\n",
        "    ckpt = torch.load(best_ckpt_path, map_location=device)\n",
        "    model.load_state_dict(ckpt[\"model_state\"])\n",
        "\n",
        "    # Save final artifact (model + history)\n",
        "    final_path = f\"models/{name}.pth\"\n",
        "    torch.save({\n",
        "        \"model_state\": model.state_dict(),\n",
        "        \"history\": history,\n",
        "        \"best_epoch\": best_epoch,\n",
        "        \"best_val_loss\": best_val\n",
        "    }, final_path)\n",
        "    print(f\"Final model saved to '{final_path}'\")\n",
        "\n",
        "# 5:41 on MPS (batch size = 64)\n",
        "# 3:34 on MPS (batch size = 128)\n",
        "# 2:45 on MPS (batch size = 256)\n",
        "# 7:50 on CPU\n",
        "# 6:20 on L4\n",
        "\n",
        "# With augmentations:\n",
        "# 5:03 on MPS (batch size = 128)\n",
        "\n",
        "# With early stopping:\n",
        "# 1:12 on MPS (batch size = 128)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf8ae466",
      "metadata": {},
      "source": [
        "#### Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb4f2ea5",
      "metadata": {},
      "outputs": [],
      "source": [
        "def display_results(path):\n",
        "    # Loss and accuracy graph\n",
        "    # Load the trained model from file\n",
        "    model = MLP(128*128).to(device)  # initialize model structure\n",
        "    checkpoint = torch.load(path, map_location=device)\n",
        "    model.load_state_dict(checkpoint[\"model_state\"])\n",
        "    history = checkpoint[\"history\"]\n",
        "\n",
        "    model.eval()  # set to evaluation mode\n",
        "\n",
        "    # Prepare x-axis for plots\n",
        "    epochs = range(1, len(history[\"train_loss\"]) + 1)\n",
        "\n",
        "    # Create figure and first axis (loss)\n",
        "    fig, ax1 = plt.subplots()\n",
        "\n",
        "    color_loss = \"tab:blue\"\n",
        "    ax1.set_xlabel(\"Epoch\")\n",
        "    ax1.set_ylabel(\"Loss\", color=color_loss)\n",
        "    ax1.plot(epochs, history[\"train_loss\"], label=\"Train Loss\", color=color_loss, linestyle=\"-\")\n",
        "    ax1.plot(epochs, history[\"val_loss\"], label=\"Val Loss\", color=color_loss, linestyle=\"--\")\n",
        "    ax1.tick_params(axis=\"y\", labelcolor=color_loss)\n",
        "\n",
        "    # Second y-axis for accuracy\n",
        "    ax2 = ax1.twinx()\n",
        "    color_acc = \"tab:orange\"\n",
        "    ax2.set_ylabel(\"Accuracy\", color=color_acc)\n",
        "    ax2.plot(epochs, history[\"train_acc\"], label=\"Train Acc\", color=color_acc, linestyle=\"-\")\n",
        "    ax2.plot(epochs, history[\"val_acc\"], label=\"Val Acc\", color=color_acc, linestyle=\"--\")\n",
        "    ax2.tick_params(axis=\"y\", labelcolor=color_acc)\n",
        "\n",
        "    # Combine legends from both axes\n",
        "    lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
        "    lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
        "    ax1.legend(lines_1 + lines_2, labels_1 + labels_2, loc=\"center right\")\n",
        "\n",
        "    plt.title(\"Loss and Accuracy over Epochs\")\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Confusion matrix\n",
        "    # Variables to track accuracy\n",
        "    test_correct, test_total = 0, 0\n",
        "\n",
        "    # Lists to store predictions and true labels for the confusion matrix\n",
        "    all_preds, all_trues = [], []\n",
        "\n",
        "    # Disable gradient computation for faster evaluation\n",
        "    with torch.no_grad():\n",
        "        # Loop through the test set in batches\n",
        "        for x, y in test_loader:\n",
        "            # Move inputs to the computation device (CPU/GPU/MPS)\n",
        "            x = x.to(device)\n",
        "            \n",
        "            # Forward pass to get raw model outputs (logits)\n",
        "            logits = model(x)\n",
        "            \n",
        "            # Get predicted class indices (highest logit per sample)\n",
        "            preds = logits.argmax(1).cpu().numpy()\n",
        "            \n",
        "            # Store predictions and ground truth labels for later\n",
        "            all_preds.append(preds)\n",
        "            all_trues.append(y.numpy())\n",
        "            \n",
        "            # Update accuracy counters\n",
        "            test_correct += (preds == y.numpy()).sum()\n",
        "            test_total   += y.size(0)\n",
        "\n",
        "    # Compute overall test accuracy\n",
        "    test_acc = test_correct / test_total\n",
        "    print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "\n",
        "    # Flatten predictions and true labels into 1D arrays\n",
        "    y_true = np.concatenate(all_trues).ravel()\n",
        "    y_pred = np.concatenate(all_preds).ravel()\n",
        "\n",
        "    # Dynamically detect classes from both true and predicted\n",
        "    class_labels = np.unique(np.concatenate((y_true, y_pred)))\n",
        "    print(f\"Detected {len(class_labels)} classes: {class_labels}\")\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=class_labels)\n",
        "\n",
        "    # Plot annotated confusion matrix\n",
        "    plt.figure(figsize=(6,6))\n",
        "    sns.heatmap(\n",
        "        cm,\n",
        "        annot=True,              # annotate all cells\n",
        "        fmt=\"d\",                 # integer format\n",
        "        cbar=True,\n",
        "        xticklabels=class_labels,\n",
        "        yticklabels=class_labels\n",
        "    )\n",
        "    plt.title(\"Confusion Matrix (Test)\")\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e87e9ec8",
      "metadata": {},
      "source": [
        "#### Baseline Performance (no augmentations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1c40998",
      "metadata": {},
      "outputs": [],
      "source": [
        "train(\"baseline\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12bc7fc8",
      "metadata": {},
      "outputs": [],
      "source": [
        "display_results(\"models/baseline.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db539ac8",
      "metadata": {},
      "source": [
        "#### Augment the normal images to fix imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8523b629",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Count the images\n",
        "normal_count = len([file for file in os.listdir(resized_normal_dir) if file.endswith(('.jpeg', '.jpg', '.png'))])\n",
        "pneumonia_count = len([file for file in os.listdir(resized_pneumonia_dir) if file.endswith(('.jpeg', '.jpg', '.png'))])\n",
        "print(f\"Normal count: {normal_count}\")\n",
        "print(f\"Pneumonia count: {pneumonia_count}\")\n",
        "\n",
        "# Augmentations\n",
        "augmentations = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1)\n",
        "])\n",
        "\n",
        "print(\"\\nRunning augmentations\")\n",
        "while normal_count < pneumonia_count:\n",
        "    for image in os.listdir(resized_normal_dir):\n",
        "        img_path = os.path.join(resized_normal_dir, image)\n",
        "        with Image.open(img_path, \"r\") as img:\n",
        "            augmented_img = augmentations(img)\n",
        "            name = f\"{img_path.split('.')[0]}_augmented.{img_path.split('.')[-1]}\"\n",
        "            augmented_img.save(os.path.join(name))\n",
        "            normal_count = len([file for file in os.listdir(resized_normal_dir) if file.endswith(('.jpeg', '.jpg', '.png'))])\n",
        "            print(f\"normal_count: {normal_count}\", end='\\r')\n",
        "            if normal_count >= pneumonia_count:\n",
        "                break\n",
        "\n",
        "print(\"\\n\\nAugmentation done\")\n",
        "normal_count = len([file for file in os.listdir(resized_normal_dir) if file.endswith(('.jpeg', '.jpg', '.png'))])\n",
        "pneumonia_count = len([file for file in os.listdir(resized_pneumonia_dir) if file.endswith(('.jpeg', '.jpg', '.png'))])\n",
        "print(f\"normal_count: {normal_count}\")\n",
        "print(f\"pneumonia_count: {pneumonia_count}\")\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "# NORMAL = 0, PNEUMONIA = 1\n",
        "dataset = datasets.ImageFolder(\n",
        "    root=\"128x128_data\",\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "print(f\"Classes: {dataset.classes}\")\n",
        "\n",
        "# Split data\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = int(0.1 * len(dataset))\n",
        "val_size = len(dataset) - train_size - test_size\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "print(f\"Train size: {len(train_dataset)}\")\n",
        "print(f\"Val size: {len(val_dataset)}\")\n",
        "print(f\"Test size: {len(test_dataset)}\")\n",
        "\n",
        "# DataLoaders\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Batch size: {batch_size}\")\n",
        "# ~6s"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e50b963b",
      "metadata": {},
      "source": [
        "#### With Augmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e4c6157",
      "metadata": {},
      "outputs": [],
      "source": [
        "train(\"augmentations\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "087f5fed",
      "metadata": {},
      "outputs": [],
      "source": [
        "display_results(\"models/augmentations.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c28cccc2",
      "metadata": {},
      "source": [
        "#### Trying a lower learning rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6df641b8",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = MLP(128*128).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "train(\"lower_learning_rate\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f608955",
      "metadata": {},
      "outputs": [],
      "source": [
        "display_results(\"models/lower_learning_rate.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca3d90d4",
      "metadata": {},
      "source": [
        "#### Extra layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ade668d",
      "metadata": {},
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_dim, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2048, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 2)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "model = MLP(128*128).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "train(\"extra_layer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4e0791a",
      "metadata": {},
      "outputs": [],
      "source": [
        "display_results(\"models/extra_layer.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acf6dcea",
      "metadata": {},
      "source": [
        "#### Two more layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75b2325f",
      "metadata": {},
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_dim, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4096, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2048, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 2)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "model = MLP(128*128).to(device)\n",
        "train(\"two_more_layers\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66abad2a",
      "metadata": {},
      "outputs": [],
      "source": [
        "display_results(\"models/two_more_layers.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf8186fa",
      "metadata": {},
      "source": [
        "# Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fe01e88",
      "metadata": {},
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 16 * 16, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 2)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "    \n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dl-venv",
      "language": "python",
      "name": "dl-venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
