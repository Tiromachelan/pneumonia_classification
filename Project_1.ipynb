{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "299b2255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stuff\n",
    "from torchvision import transforms, datasets\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import platform\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "108555a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete images in 128x128_data if needed\n",
    "normal_dir = \"128x128_data/NORMAL\"\n",
    "pneumonia_dir = \"128x128_data/PNEUMONIA\"\n",
    "\n",
    "for file in os.listdir(normal_dir) + os.listdir(pneumonia_dir):\n",
    "    img_path = os.path.join(normal_dir if file in os.listdir(normal_dir) else pneumonia_dir, file)\n",
    "    os.remove(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76178a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device.type}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f630717",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93e9baa",
   "metadata": {},
   "source": [
    "#### Resize the images to 128 x 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ad82ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest image dimensions: (384, 127)\n",
      "Smallest image path: data/PNEUMONIA/person407_virus_811.jpeg\n"
     ]
    }
   ],
   "source": [
    "# Set up paths\n",
    "normal_dir = \"data/NORMAL\"\n",
    "pneumonia_dir = \"data/PNEUMONIA\"\n",
    "\n",
    "# Find which images have the smallest size\n",
    "min_size = float('inf')\n",
    "min_dimensions = (float('inf'), float('inf'))\n",
    "smallest_img_path = \"\"\n",
    "\n",
    "for image in os.listdir(normal_dir) + os.listdir(pneumonia_dir):\n",
    "    if image.endswith((\".jpeg\", \".jpg\", \".png\")):\n",
    "        img_path = os.path.join(normal_dir if image in os.listdir(normal_dir) else pneumonia_dir, image)\n",
    "        with Image.open(img_path, \"r\") as img:\n",
    "            width, height = img.size\n",
    "            if width * height < min_size:\n",
    "                min_size = width * height\n",
    "                min_dimensions = (width, height)\n",
    "                smallest_img_path = img_path\n",
    "\n",
    "print(f\"Smallest image dimensions: {min_dimensions}\")\n",
    "print(f\"Smallest image path: {smallest_img_path}\")\n",
    "\n",
    "# Paths for resized images\n",
    "resized_normal_dir = \"128x128_data/NORMAL\"\n",
    "resized_pneumonia_dir = \"128x128_data/PNEUMONIA\"\n",
    "\n",
    "# Resize all images to 128x128 pixels and save them\n",
    "for image in os.listdir(normal_dir) + os.listdir(pneumonia_dir):\n",
    "    if image.endswith((\".jpeg\", \".jpg\", \".png\")):\n",
    "        img_path = os.path.join(normal_dir if image in os.listdir(normal_dir) else pneumonia_dir, image)\n",
    "        with Image.open(img_path, \"r\") as img:\n",
    "            img = img.convert(\"L\")  # Convert to grayscale\n",
    "            width, height = img.size\n",
    "            if width > height:\n",
    "                cropped_width = 128\n",
    "                cropped_height = int(height * 128 / width)\n",
    "            else:\n",
    "                cropped_height = 128\n",
    "                cropped_width = int(width * 128 / height)\n",
    "            img = img.resize((cropped_width, cropped_height)) # Resize preserving ratio\n",
    "            left = 0\n",
    "            upper = (cropped_height - 128) // 2\n",
    "            right = 128\n",
    "            lower = upper + 128\n",
    "            img = img.crop((left, upper, right, lower)) # Center crop\n",
    "\n",
    "            if \"NORMAL\" in img_path:\n",
    "                save_path = os.path.join(resized_normal_dir, image)\n",
    "            else:\n",
    "                save_path = os.path.join(resized_pneumonia_dir, image)\n",
    "            img.save(save_path)\n",
    "\n",
    "# ~30 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c2ba9d",
   "metadata": {},
   "source": [
    "#### Ensure that all of the images are the same shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a607b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 images with incorrect shape\n"
     ]
    }
   ],
   "source": [
    "# Convert each image to a tensor and ensure they are all 1 x 128 x 128\n",
    "counter = 0\n",
    "for image in os.listdir(resized_normal_dir) + os.listdir(resized_pneumonia_dir):\n",
    "    if image.endswith((\".jpeg\", \".jpg\", \".png\")):\n",
    "        img_path = os.path.join(resized_normal_dir if image in os.listdir(resized_normal_dir) else resized_pneumonia_dir, image)\n",
    "        with Image.open(img_path, \"r\") as img:\n",
    "            img_tensor = transforms.ToTensor()(img)\n",
    "            if img_tensor.shape != (1, 128, 128):\n",
    "                print(f\"{image} has shape {img_tensor.shape}\")\n",
    "                counter += 1\n",
    "print(f\"{counter} images with incorrect shape\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd2efaa",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7105ecb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['NORMAL', 'PNEUMONIA']\n",
      "Train size: 4684\n",
      "Val size: 587\n",
      "Test size: 585\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(\n",
    "    root=\"128x128_data\",\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "print(f\"Classes: {dataset.classes}\")\n",
    "\n",
    "# Split data\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = int(0.1 * len(dataset))\n",
    "val_size = len(dataset) - train_size - test_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "print(f\"Train size: {len(train_dataset)}\")\n",
    "print(f\"Val size: {len(val_dataset)}\")\n",
    "print(f\"Test size: {len(test_dataset)}\")\n",
    "\n",
    "# DataLoaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86297407",
   "metadata": {},
   "source": [
    "# Fully Connected Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08651837",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b754011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the network\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_dim, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 2)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d951cd",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fc2f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training parameters\n",
    "model = MLP(128*128).to(device)\n",
    "loss = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "epochs = 100\n",
    "history = {\n",
    "    \"train_loss\": [], \"train_acc\": [],\n",
    "    \"val_loss\":   [], \"val_acc\":   []\n",
    "}\n",
    "\n",
    "# Calculate accuracy from logits\n",
    "def accuracy_from_logits(logits, y):\n",
    "    preds = logits.argmax(1)  # choose class with highest predicted score\n",
    "    return (preds == y).float().mean().item()  # fraction of correct predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22484aef",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a88ccb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-venv",
   "language": "python",
   "name": "dl-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
