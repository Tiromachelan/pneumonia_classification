{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "299b2255",
      "metadata": {
        "id": "299b2255"
      },
      "outputs": [],
      "source": [
        "# Import stuff\n",
        "from torchvision import transforms, datasets\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import platform\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import time\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f015c7c0",
      "metadata": {
        "id": "f015c7c0"
      },
      "source": [
        "#### Run this if in Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "02672ac5",
      "metadata": {
        "id": "02672ac5",
        "outputId": "302404d2-fcba-4800-a969-f62380cb9f35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '128x128_data': No such file or directory\n",
            "rm: cannot remove 'pneumonia_classification': No such file or directory\n",
            "Cloning into 'pneumonia_classification'...\n",
            "remote: Enumerating objects: 5855, done.\u001b[K\n",
            "remote: Counting objects: 100% (5855/5855), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5846/5846), done.\u001b[K\n",
            "remote: Total 5855 (delta 8), reused 5851 (delta 6), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (5855/5855), 13.85 MiB | 24.07 MiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n"
          ]
        }
      ],
      "source": [
        "def in_colab() -> bool:\n",
        "    try:\n",
        "        import google.colab\n",
        "        return True\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "REPO_URL = \"https://github.com/Tiromachelan/pneumonia_classification.git\"\n",
        "\n",
        "if in_colab():\n",
        "    if not Path(\"pneumonia_classification\").exists():\n",
        "        !rm -r 128x128_data\n",
        "        !rm -r pneumonia_classification\n",
        "        !git clone {REPO_URL}\n",
        "        !mv pneumonia_classification/128x128_data ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "108555a3",
      "metadata": {
        "id": "108555a3"
      },
      "outputs": [],
      "source": [
        "# Delete images in 128x128_data if needed\n",
        "normal_dir = \"128x128_data/NORMAL\"\n",
        "pneumonia_dir = \"128x128_data/PNEUMONIA\"\n",
        "\n",
        "for file in os.listdir(normal_dir) + os.listdir(pneumonia_dir):\n",
        "    img_path = os.path.join(normal_dir if file in os.listdir(normal_dir) else pneumonia_dir, file)\n",
        "    os.remove(img_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "76178a00",
      "metadata": {
        "id": "76178a00",
        "outputId": "f838c40a-40bb-43ec-a778-fd9ad5146405",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Select device\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(f\"Using device: {device.type}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f630717",
      "metadata": {
        "id": "7f630717"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f93e9baa",
      "metadata": {
        "id": "f93e9baa"
      },
      "source": [
        "#### Resize the images to 128 x 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ad82ffd",
      "metadata": {
        "id": "8ad82ffd"
      },
      "outputs": [],
      "source": [
        "# Set up paths\n",
        "normal_dir = \"data/NORMAL\"\n",
        "pneumonia_dir = \"data/PNEUMONIA\"\n",
        "\n",
        "# Find which images have the smallest size\n",
        "min_size = float('inf')\n",
        "min_dimensions = (float('inf'), float('inf'))\n",
        "smallest_img_path = \"\"\n",
        "\n",
        "for image in os.listdir(normal_dir) + os.listdir(pneumonia_dir):\n",
        "    if image.endswith((\".jpeg\", \".jpg\", \".png\")):\n",
        "        img_path = os.path.join(normal_dir if image in os.listdir(normal_dir) else pneumonia_dir, image)\n",
        "        with Image.open(img_path, \"r\") as img:\n",
        "            width, height = img.size\n",
        "            if width * height < min_size:\n",
        "                min_size = width * height\n",
        "                min_dimensions = (width, height)\n",
        "                smallest_img_path = img_path\n",
        "\n",
        "print(f\"Smallest image dimensions: {min_dimensions}\")\n",
        "print(f\"Smallest image path: {smallest_img_path}\")\n",
        "\n",
        "# Paths for resized images\n",
        "resized_normal_dir = \"128x128_data/NORMAL\"\n",
        "resized_pneumonia_dir = \"128x128_data/PNEUMONIA\"\n",
        "\n",
        "# Resize all images to 128x128 pixels and save them\n",
        "for image in os.listdir(normal_dir) + os.listdir(pneumonia_dir):\n",
        "    if image.endswith((\".jpeg\", \".jpg\", \".png\")):\n",
        "        img_path = os.path.join(normal_dir if image in os.listdir(normal_dir) else pneumonia_dir, image)\n",
        "        with Image.open(img_path, \"r\") as img:\n",
        "            img = img.convert(\"L\")  # Convert to grayscale\n",
        "            width, height = img.size\n",
        "            if width > height:\n",
        "                cropped_width = 128\n",
        "                cropped_height = int(height * 128 / width)\n",
        "            else:\n",
        "                cropped_height = 128\n",
        "                cropped_width = int(width * 128 / height)\n",
        "            img = img.resize((cropped_width, cropped_height)) # Resize preserving ratio\n",
        "            left = 0\n",
        "            upper = (cropped_height - 128) // 2\n",
        "            right = 128\n",
        "            lower = upper + 128\n",
        "            img = img.crop((left, upper, right, lower)) # Center crop\n",
        "\n",
        "            if \"NORMAL\" in img_path:\n",
        "                save_path = os.path.join(resized_normal_dir, image)\n",
        "            else:\n",
        "                save_path = os.path.join(resized_pneumonia_dir, image)\n",
        "            img.save(save_path)\n",
        "\n",
        "# ~30 seconds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94c2ba9d",
      "metadata": {
        "id": "94c2ba9d"
      },
      "source": [
        "#### Ensure that all of the images are the same shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a607b95",
      "metadata": {
        "id": "7a607b95"
      },
      "outputs": [],
      "source": [
        "# Convert each image to a tensor and ensure they are all 1 x 128 x 128\n",
        "counter = 0\n",
        "for image in os.listdir(resized_normal_dir) + os.listdir(resized_pneumonia_dir):\n",
        "    if image.endswith((\".jpeg\", \".jpg\", \".png\")):\n",
        "        img_path = os.path.join(resized_normal_dir if image in os.listdir(resized_normal_dir) else resized_pneumonia_dir, image)\n",
        "        with Image.open(img_path, \"r\") as img:\n",
        "            img_tensor = transforms.ToTensor()(img)\n",
        "            if img_tensor.shape != (1, 128, 128):\n",
        "                print(f\"{image} has shape {img_tensor.shape}\")\n",
        "                counter += 1\n",
        "print(f\"{counter} images with incorrect shape\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfd2efaa",
      "metadata": {
        "id": "dfd2efaa"
      },
      "source": [
        "#### Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7105ecb2",
      "metadata": {
        "id": "7105ecb2",
        "outputId": "74ec4ee8-3a17-4278-8280-61c866a59dea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['NORMAL', 'PNEUMONIA']\n",
            "Train size: 4684\n",
            "Val size: 587\n",
            "Test size: 585\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "dataset = datasets.ImageFolder(\n",
        "    root=\"128x128_data\",\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "print(f\"Classes: {dataset.classes}\")\n",
        "\n",
        "# Split data\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = int(0.1 * len(dataset))\n",
        "val_size = len(dataset) - train_size - test_size\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "print(f\"Train size: {len(train_dataset)}\")\n",
        "print(f\"Val size: {len(val_dataset)}\")\n",
        "print(f\"Test size: {len(test_dataset)}\")\n",
        "\n",
        "# DataLoaders\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86297407",
      "metadata": {
        "id": "86297407"
      },
      "source": [
        "# Fully Connected Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08651837",
      "metadata": {
        "id": "08651837"
      },
      "source": [
        "#### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8b754011",
      "metadata": {
        "id": "8b754011"
      },
      "outputs": [],
      "source": [
        "# Define the network\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_dim, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2048, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 2)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11d951cd",
      "metadata": {
        "id": "11d951cd"
      },
      "source": [
        "#### Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b9fc2f0a",
      "metadata": {
        "id": "b9fc2f0a"
      },
      "outputs": [],
      "source": [
        "# Define the training parameters\n",
        "model = MLP(128*128).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
        "epochs = 100\n",
        "history = {\n",
        "    \"train_loss\": [], \"train_acc\": [],\n",
        "    \"val_loss\":   [], \"val_acc\":   []\n",
        "}\n",
        "\n",
        "# Calculate accuracy from logits\n",
        "def accuracy_from_logits(logits, y):\n",
        "    preds = logits.argmax(1)  # choose class with highest predicted score\n",
        "    return (preds == y).float().mean().item()  # fraction of correct predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22484aef",
      "metadata": {
        "id": "22484aef"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "7a88ccb4",
      "metadata": {
        "id": "7a88ccb4",
        "outputId": "d7654a33-c93d-4be5-fd6e-26bf4948bb06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 00 | train: loss=14374.0622, acc=0.7205 | val: loss=168.0005, acc=0.7496 | time: 4.72s\n",
            "Epoch 01 | train: loss=874.1040, acc=0.7319 | val: loss=2.5472, acc=0.7428 | time: 3.86s\n",
            "Epoch 02 | train: loss=3.4634, acc=0.7316 | val: loss=0.5656, acc=0.7445 | time: 3.78s\n",
            "Epoch 03 | train: loss=0.5681, acc=0.7316 | val: loss=0.5349, acc=0.7445 | time: 3.82s\n",
            "Epoch 04 | train: loss=0.7637, acc=0.7316 | val: loss=0.5702, acc=0.7445 | time: 3.81s\n",
            "Epoch 05 | train: loss=0.5831, acc=0.7316 | val: loss=0.5683, acc=0.7445 | time: 3.84s\n",
            "Epoch 06 | train: loss=0.5862, acc=0.7316 | val: loss=0.5724, acc=0.7445 | time: 3.81s\n",
            "Epoch 07 | train: loss=0.5837, acc=0.7316 | val: loss=0.5685, acc=0.7445 | time: 3.80s\n",
            "Epoch 08 | train: loss=0.5847, acc=0.7316 | val: loss=0.5738, acc=0.7445 | time: 3.81s\n",
            "Epoch 09 | train: loss=0.5821, acc=0.7316 | val: loss=0.5763, acc=0.7445 | time: 3.88s\n",
            "Epoch 10 | train: loss=0.5837, acc=0.7316 | val: loss=0.5690, acc=0.7445 | time: 3.84s\n",
            "Epoch 11 | train: loss=0.5874, acc=0.7316 | val: loss=0.5737, acc=0.7445 | time: 3.82s\n",
            "Epoch 12 | train: loss=0.5840, acc=0.7316 | val: loss=0.5698, acc=0.7445 | time: 3.82s\n",
            "Epoch 13 | train: loss=0.5828, acc=0.7316 | val: loss=0.5727, acc=0.7445 | time: 3.83s\n",
            "Epoch 14 | train: loss=0.5820, acc=0.7316 | val: loss=0.5689, acc=0.7445 | time: 3.81s\n",
            "Epoch 15 | train: loss=0.5842, acc=0.7316 | val: loss=0.5693, acc=0.7445 | time: 3.84s\n",
            "Epoch 16 | train: loss=0.5841, acc=0.7316 | val: loss=0.5687, acc=0.7445 | time: 3.81s\n",
            "Epoch 17 | train: loss=0.5838, acc=0.7316 | val: loss=0.5685, acc=0.7445 | time: 3.82s\n",
            "Epoch 18 | train: loss=0.5834, acc=0.7316 | val: loss=0.5687, acc=0.7445 | time: 3.83s\n",
            "Epoch 19 | train: loss=0.5825, acc=0.7316 | val: loss=0.5741, acc=0.7445 | time: 3.80s\n",
            "Epoch 20 | train: loss=0.5872, acc=0.7316 | val: loss=0.5684, acc=0.7445 | time: 3.80s\n",
            "Epoch 21 | train: loss=0.5852, acc=0.7316 | val: loss=0.5715, acc=0.7445 | time: 3.84s\n",
            "Epoch 22 | train: loss=0.5848, acc=0.7316 | val: loss=0.5690, acc=0.7445 | time: 3.84s\n",
            "Epoch 23 | train: loss=0.5833, acc=0.7316 | val: loss=0.5717, acc=0.7445 | time: 3.80s\n",
            "Epoch 24 | train: loss=0.5829, acc=0.7316 | val: loss=0.5684, acc=0.7445 | time: 3.84s\n",
            "Epoch 25 | train: loss=0.5841, acc=0.7316 | val: loss=0.5805, acc=0.7445 | time: 3.82s\n",
            "Epoch 26 | train: loss=0.5851, acc=0.7316 | val: loss=0.5697, acc=0.7445 | time: 3.81s\n",
            "Epoch 27 | train: loss=0.5835, acc=0.7316 | val: loss=0.5694, acc=0.7445 | time: 3.84s\n",
            "Epoch 28 | train: loss=0.5827, acc=0.7316 | val: loss=0.5690, acc=0.7445 | time: 3.81s\n",
            "Epoch 29 | train: loss=0.5829, acc=0.7316 | val: loss=0.5688, acc=0.7445 | time: 3.78s\n",
            "Epoch 30 | train: loss=0.5835, acc=0.7316 | val: loss=0.5685, acc=0.7445 | time: 3.81s\n",
            "Epoch 31 | train: loss=0.5833, acc=0.7316 | val: loss=0.5685, acc=0.7445 | time: 3.82s\n",
            "Epoch 32 | train: loss=0.5822, acc=0.7316 | val: loss=0.5710, acc=0.7445 | time: 3.78s\n",
            "Epoch 33 | train: loss=0.5852, acc=0.7316 | val: loss=0.5686, acc=0.7445 | time: 3.82s\n",
            "Epoch 34 | train: loss=0.5815, acc=0.7316 | val: loss=0.5684, acc=0.7445 | time: 3.83s\n",
            "Epoch 35 | train: loss=0.5846, acc=0.7316 | val: loss=0.5712, acc=0.7445 | time: 3.78s\n",
            "Epoch 36 | train: loss=0.5830, acc=0.7316 | val: loss=0.5722, acc=0.7445 | time: 3.81s\n",
            "Epoch 37 | train: loss=0.5831, acc=0.7316 | val: loss=0.5717, acc=0.7445 | time: 3.85s\n",
            "Epoch 38 | train: loss=0.5850, acc=0.7316 | val: loss=0.5701, acc=0.7445 | time: 3.84s\n",
            "Epoch 39 | train: loss=0.5825, acc=0.7316 | val: loss=0.5799, acc=0.7445 | time: 3.82s\n",
            "Epoch 40 | train: loss=0.5827, acc=0.7316 | val: loss=0.5787, acc=0.7445 | time: 3.78s\n",
            "Epoch 41 | train: loss=0.5836, acc=0.7316 | val: loss=0.5698, acc=0.7445 | time: 3.78s\n",
            "Epoch 42 | train: loss=0.5848, acc=0.7316 | val: loss=0.5692, acc=0.7445 | time: 3.83s\n",
            "Epoch 43 | train: loss=0.5835, acc=0.7316 | val: loss=0.5707, acc=0.7445 | time: 3.80s\n",
            "Epoch 44 | train: loss=0.5848, acc=0.7316 | val: loss=0.5707, acc=0.7445 | time: 3.78s\n",
            "Epoch 45 | train: loss=0.5829, acc=0.7316 | val: loss=0.5684, acc=0.7445 | time: 3.81s\n",
            "Epoch 46 | train: loss=0.5869, acc=0.7316 | val: loss=0.5691, acc=0.7445 | time: 3.80s\n",
            "Epoch 47 | train: loss=0.5829, acc=0.7316 | val: loss=0.5683, acc=0.7445 | time: 3.84s\n",
            "Epoch 48 | train: loss=0.5829, acc=0.7316 | val: loss=0.5686, acc=0.7445 | time: 3.82s\n",
            "Epoch 49 | train: loss=0.5830, acc=0.7316 | val: loss=0.5683, acc=0.7445 | time: 3.83s\n",
            "Epoch 50 | train: loss=0.5839, acc=0.7316 | val: loss=0.5685, acc=0.7445 | time: 3.84s\n",
            "Epoch 51 | train: loss=0.5828, acc=0.7316 | val: loss=0.5686, acc=0.7445 | time: 3.84s\n",
            "Epoch 52 | train: loss=0.5849, acc=0.7316 | val: loss=0.5695, acc=0.7445 | time: 3.82s\n",
            "Epoch 53 | train: loss=0.5839, acc=0.7316 | val: loss=0.5691, acc=0.7445 | time: 3.82s\n",
            "Epoch 54 | train: loss=0.5830, acc=0.7316 | val: loss=0.5688, acc=0.7445 | time: 3.83s\n",
            "Epoch 55 | train: loss=0.5826, acc=0.7316 | val: loss=0.5703, acc=0.7445 | time: 3.82s\n",
            "Epoch 56 | train: loss=0.5830, acc=0.7316 | val: loss=0.5683, acc=0.7445 | time: 3.78s\n",
            "Epoch 57 | train: loss=0.5849, acc=0.7316 | val: loss=0.5738, acc=0.7445 | time: 3.79s\n",
            "Epoch 58 | train: loss=0.5870, acc=0.7316 | val: loss=0.5733, acc=0.7445 | time: 3.80s\n",
            "Epoch 59 | train: loss=0.5861, acc=0.7316 | val: loss=0.5687, acc=0.7445 | time: 3.79s\n",
            "Epoch 60 | train: loss=0.5844, acc=0.7316 | val: loss=0.5688, acc=0.7445 | time: 3.79s\n",
            "Epoch 61 | train: loss=0.5834, acc=0.7316 | val: loss=0.5684, acc=0.7445 | time: 3.81s\n",
            "Epoch 62 | train: loss=0.5827, acc=0.7316 | val: loss=0.5683, acc=0.7445 | time: 3.85s\n",
            "Epoch 63 | train: loss=0.5873, acc=0.7316 | val: loss=0.5741, acc=0.7445 | time: 3.83s\n",
            "Epoch 64 | train: loss=0.5842, acc=0.7316 | val: loss=0.5686, acc=0.7445 | time: 3.85s\n",
            "Epoch 65 | train: loss=0.5841, acc=0.7316 | val: loss=0.5712, acc=0.7445 | time: 3.83s\n",
            "Epoch 66 | train: loss=0.5889, acc=0.7316 | val: loss=0.5780, acc=0.7445 | time: 3.87s\n",
            "Epoch 67 | train: loss=0.5836, acc=0.7316 | val: loss=0.5706, acc=0.7445 | time: 3.83s\n",
            "Epoch 68 | train: loss=0.5831, acc=0.7316 | val: loss=0.5727, acc=0.7445 | time: 3.84s\n",
            "Epoch 69 | train: loss=0.5849, acc=0.7316 | val: loss=0.5684, acc=0.7445 | time: 3.86s\n",
            "Epoch 70 | train: loss=0.5834, acc=0.7316 | val: loss=0.5685, acc=0.7445 | time: 3.82s\n",
            "Epoch 71 | train: loss=0.5838, acc=0.7316 | val: loss=0.5686, acc=0.7445 | time: 3.80s\n",
            "Epoch 72 | train: loss=0.5828, acc=0.7316 | val: loss=0.5683, acc=0.7445 | time: 3.81s\n",
            "Epoch 73 | train: loss=0.5852, acc=0.7316 | val: loss=0.5714, acc=0.7445 | time: 3.80s\n",
            "Epoch 74 | train: loss=0.5835, acc=0.7316 | val: loss=0.5706, acc=0.7445 | time: 3.78s\n",
            "Epoch 75 | train: loss=0.5865, acc=0.7316 | val: loss=0.5694, acc=0.7445 | time: 3.82s\n",
            "Epoch 76 | train: loss=0.5865, acc=0.7316 | val: loss=0.5759, acc=0.7445 | time: 3.80s\n",
            "Epoch 77 | train: loss=0.5844, acc=0.7316 | val: loss=0.5775, acc=0.7445 | time: 3.80s\n",
            "Epoch 78 | train: loss=0.5850, acc=0.7316 | val: loss=0.5718, acc=0.7445 | time: 3.83s\n",
            "Epoch 79 | train: loss=0.5834, acc=0.7316 | val: loss=0.5697, acc=0.7445 | time: 3.80s\n",
            "Epoch 80 | train: loss=0.5846, acc=0.7316 | val: loss=0.5738, acc=0.7445 | time: 3.82s\n",
            "Epoch 81 | train: loss=0.5851, acc=0.7316 | val: loss=0.5684, acc=0.7445 | time: 3.82s\n",
            "Epoch 82 | train: loss=0.5839, acc=0.7316 | val: loss=0.5746, acc=0.7445 | time: 3.83s\n",
            "Epoch 83 | train: loss=0.5844, acc=0.7316 | val: loss=0.5691, acc=0.7445 | time: 3.82s\n",
            "Epoch 84 | train: loss=0.5830, acc=0.7316 | val: loss=0.5737, acc=0.7445 | time: 3.84s\n",
            "Epoch 85 | train: loss=0.5831, acc=0.7316 | val: loss=0.5687, acc=0.7445 | time: 3.79s\n",
            "Epoch 86 | train: loss=0.5832, acc=0.7316 | val: loss=0.5686, acc=0.7445 | time: 3.81s\n",
            "Epoch 87 | train: loss=0.5832, acc=0.7316 | val: loss=0.5752, acc=0.7445 | time: 3.83s\n",
            "Epoch 88 | train: loss=0.5842, acc=0.7316 | val: loss=0.5690, acc=0.7445 | time: 3.77s\n",
            "Epoch 89 | train: loss=0.5854, acc=0.7316 | val: loss=0.5693, acc=0.7445 | time: 3.80s\n",
            "Epoch 90 | train: loss=0.5839, acc=0.7316 | val: loss=0.5684, acc=0.7445 | time: 3.80s\n",
            "Epoch 91 | train: loss=0.5839, acc=0.7316 | val: loss=0.5685, acc=0.7445 | time: 3.83s\n",
            "Epoch 92 | train: loss=0.5827, acc=0.7316 | val: loss=0.5720, acc=0.7445 | time: 3.79s\n",
            "Epoch 93 | train: loss=0.5843, acc=0.7316 | val: loss=0.5696, acc=0.7445 | time: 3.85s\n",
            "Epoch 94 | train: loss=0.5845, acc=0.7316 | val: loss=0.5684, acc=0.7445 | time: 3.80s\n",
            "Epoch 95 | train: loss=0.5836, acc=0.7316 | val: loss=0.5841, acc=0.7445 | time: 3.82s\n",
            "Epoch 96 | train: loss=0.5863, acc=0.7316 | val: loss=0.5692, acc=0.7445 | time: 3.87s\n",
            "Epoch 97 | train: loss=0.5831, acc=0.7316 | val: loss=0.5688, acc=0.7445 | time: 3.85s\n",
            "Epoch 98 | train: loss=0.5840, acc=0.7316 | val: loss=0.5752, acc=0.7445 | time: 3.81s\n",
            "Epoch 99 | train: loss=0.5849, acc=0.7316 | val: loss=0.5686, acc=0.7445 | time: 3.80s\n",
            "\n",
            "Total training time: 382.68s\n"
          ]
        }
      ],
      "source": [
        "train_start_time = time.time()\n",
        "for epoch in range(epochs):\n",
        "    epoch_start_time = time.time()\n",
        "\n",
        "    # Training\n",
        "    model.train()\n",
        "    running_loss, running_correct, total = 0.0, 0, 0\n",
        "\n",
        "    for x, y in train_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        logits = model(x)\n",
        "        loss = criterion(logits, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * x.size(0)\n",
        "        running_correct += (logits.argmax(1) == y).sum().item()\n",
        "        total += x.size(0)\n",
        "\n",
        "    train_loss = running_loss / total\n",
        "    train_acc = running_correct / total\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_running_loss, val_running_correct, val_total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in val_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "            val_running_loss += loss.item() * x.size(0)\n",
        "            val_running_correct += (logits.argmax(1) == y).sum().item()\n",
        "            val_total += x.size(0)\n",
        "\n",
        "    val_loss = val_running_loss / val_total\n",
        "    val_acc  = val_running_correct / val_total\n",
        "\n",
        "    history[\"train_loss\"].append(train_loss)\n",
        "    history[\"train_acc\"].append(train_acc)\n",
        "    history[\"val_loss\"].append(val_loss)\n",
        "    history[\"val_acc\"].append(val_acc)\n",
        "\n",
        "    epoch_time = time.time() - epoch_start_time\n",
        "    print(f\"Epoch {epoch:02d} | \"\n",
        "          f\"train: loss={train_loss:.4f}, acc={train_acc:.4f} | \"\n",
        "          f\"val: loss={val_loss:.4f}, acc={val_acc:.4f} | \"\n",
        "          f\"time: {epoch_time:.2f}s\")\n",
        "\n",
        "# Total training time\n",
        "total_time = time.time() - train_start_time\n",
        "print(f\"\\nTotal training time: {total_time:.2f}s\")\n",
        "\n",
        "# Save the trained model\n",
        "torch.save({\n",
        "    \"model_state\": model.state_dict(),\n",
        "    \"history\": history\n",
        "}, \"mlp_relu_128x128.pth\")\n",
        "\n",
        "# 5:41 on MPS\n",
        "# 7:50 on CPU\n",
        "# 6:20 on L4"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dl-venv",
      "language": "python",
      "name": "dl-venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}